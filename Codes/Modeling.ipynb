{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH-2xnFeMQM"
      },
      "source": [
        "# Inclusive Multiple Modeling (IMM) for Calculating Subsidence Vulnerability Index (SVI)\n",
        "\n",
        "Created on Sunday November 5 11:00:00 2023\n",
        "Updated on Thersday March 21 16:00:00 2024\n",
        "\n",
        "@author: Mehdi Rahmati\n",
        "Email: mehdirmti@gmail.com, m.rahmati@fz-juelich.de\n",
        "\n",
        "Description:\n",
        "This script provides IMM formulation for modeling SVI at two levels, in which Level 1 ALPRIFT data layers are input datasets, and the normalized subsidence by InSAR processing is the label dataset. Also, at Level 2, the predicted SVI by Level 1 models is input datasets for Level 2 model, and the label dataset is the same as Level 1. In this formulation, the RF and SVM are the Level 1 models, and RF plays the combiner role at Level 2.\n",
        "\n",
        "More detailed information can be found in the article published at the following link:\n",
        "https://www.XXX.XXX\n",
        "\n",
        "To be cited as:\n",
        "Mohammadi et al., 202X.AI-Powered Multiple Modeling of Land Subsidence Vulnerability based on Cluster Analysis due to Groundwater Over-abstraction. XXX, XX, XX-XX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm52otQ8kleY"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx_JJU8XeMQO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from skimage import io  # !pip install scikit-image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import colors\n",
        "from osgeo import gdal, osr # to work with GeoTiff files (pip install gdal)\n",
        "\n",
        "#Import metrices for accuracy check\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# import sklearn model selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Import RF and SVM classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC # to do SVM classification\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from math import isnan\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsubx6oAkR6_"
      },
      "source": [
        "# Define fucntions to read and write GeoTiff files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUPQcMoikTrD"
      },
      "outputs": [],
      "source": [
        "# read data from GeoTiff file\n",
        "def ReadGeoTiff(zipFile, fileName):\n",
        "    # To open  file from zipfile without extracting it\n",
        "    raster = gdal.Open(\"/vsizip/\" + zipFile + \"/\" + fileName)\n",
        "\n",
        "    # get the existing coordinate system\n",
        "    old_cs = osr.SpatialReference()\n",
        "    old_cs.ImportFromWkt(raster.GetProjectionRef())\n",
        "\n",
        "    # Projection\n",
        "    Projection = raster.GetProjection()\n",
        "\n",
        "    # Number of bands\n",
        "    NumberBands = raster.RasterCount\n",
        "\n",
        "    # Metadata for the raster dataset\n",
        "    Metadata = raster.GetMetadata()\n",
        "\n",
        "    # Read the raster band as separate variable\n",
        "    dataArray = np.array(raster.ReadAsArray())\n",
        "\n",
        "    # Dimensions\n",
        "    [rows, cols] = dataArray.shape\n",
        "\n",
        "    # get geotransform\n",
        "    geotransform = raster.GetGeoTransform()\n",
        "\n",
        "    # create the new coordinate system\n",
        "    wgs84_wkt = \"\"\"\n",
        "    GEOGCS[\"WGS 84\",\n",
        "        DATUM[\"WGS_1984\",\n",
        "            SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
        "                AUTHORITY[\"EPSG\",\"7030\"]],\n",
        "            AUTHORITY[\"EPSG\",\"6326\"]],\n",
        "        PRIMEM[\"Greenwich\",0,\n",
        "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
        "        UNIT[\"degree\",0.01745329251994328,\n",
        "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
        "        AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
        "    new_cs = osr.SpatialReference()\n",
        "    new_cs.ImportFromWkt(wgs84_wkt)\n",
        "\n",
        "    # create a transform object to convert between coordinate systems\n",
        "    transform = osr.CoordinateTransformation(old_cs,new_cs)\n",
        "\n",
        "    # get the width and height of the raster file\n",
        "    width = raster.RasterXSize\n",
        "    height = raster.RasterYSize\n",
        "\n",
        "    # get the points to transform (minx, miny, maxx, and maxy)\n",
        "    minx = geotransform[0]\n",
        "    miny = geotransform[3] + width*geotransform[4] + height*geotransform[5]\n",
        "    maxx = geotransform[0] + width*geotransform[1] + height*geotransform[2]\n",
        "    maxy = geotransform[3]\n",
        "\n",
        "    # get the coordinates of minx, miny, maxx, and maxy in lat and long (decimal degree)\n",
        "    min_lat, min_long, _ = transform.TransformPoint(minx, miny)\n",
        "    max_lat, max_long, _ = transform.TransformPoint(maxx, maxy)\n",
        "\n",
        "    # retrun data and properties \n",
        "    return {'data': dataArray,\n",
        "            'Projection': Projection,\n",
        "            'rows': rows,\n",
        "            'cols': cols,\n",
        "            'NumberBands': NumberBands,\n",
        "            'Metadata': Metadata,\n",
        "            'geotransform': geotransform,\n",
        "            'lat_minmax': [min_lat, max_lat],\n",
        "            'long_minmax': [min_long, max_long]}\n",
        "\n",
        "# write data into new geotiff\n",
        "def WriteGeoTiff(arr_out, outFileName, cols, rows, geotransform, Projection):\n",
        "    driver = gdal.GetDriverByName(\"GTiff\")\n",
        "    outdata = driver.Create(outFileName, cols, rows, 1, gdal.GDT_UInt16)\n",
        "\n",
        "    outdata.SetGeoTransform(geotransform)##sets same geotransform as input\n",
        "    outdata.SetProjection(Projection)##sets same projection as input\n",
        "    outdata.GetRasterBand(1).WriteArray(arr_out)\n",
        "    outdata.GetRasterBand(1).SetNoDataValue(10000)##if you want these values transparent\n",
        "    outdata.FlushCache() ##saves to disk!!\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPbF59qnkhOq"
      },
      "source": [
        "# Read SVI image as geotiff for further use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URtWmetRkkUp"
      },
      "outputs": [],
      "source": [
        "SVI_geotiff = ReadGeoTiff(r\"../Data/Layers.zip\", \"SVI.tif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciq2lo4yk5L_"
      },
      "source": [
        "# Load data into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "aQKvpr34l8ux",
        "outputId": "e109cba4-d852-484f-97d3-d55acdf9ac1c"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame()\n",
        "with ZipFile(\"../Data/Layers.zip\", \"r\") as zipFile:\n",
        "\n",
        "  image_names = [f for f in zipFile.namelist() if f.endswith('.tif')]\n",
        "  for i, img in enumerate(image_names):\n",
        "    with zipFile.open(img) as file:\n",
        "      image = io.imread(file)\n",
        "      if i == 0:\n",
        "        # Keep the number of rows and columns for future use\n",
        "        n_row, n_col = image.shape\n",
        "      else:\n",
        "        # check if all images have the same size\n",
        "        if n_row != image.shape[0] or n_col != image.shape[1]:\n",
        "          print(\"The feature images are not the same size. Check your input images and restart the calculations!\")\n",
        "          break\n",
        "      # flatten 2D data to 1D to store in DataFrame\n",
        "      if file.name[:-4] == 'L':\n",
        "        image = np.array(image, dtype='object').flatten()\n",
        "      else:\n",
        "        image = np.array(image, dtype='float32').flatten()\n",
        "\n",
        "      data[\"{}\".format(file.name[:-4])] = image\n",
        "  print(\"List of variables inside the final data dictionary: \")\n",
        "  print(\"A: Aquifer media\")\n",
        "  print(\"L: Land use\")\n",
        "  print(\"P: Pumping of groundwater\")\n",
        "  print(\"R: Recharge\")\n",
        "  print(\"I: Impacts induced by aquifer thickness\")\n",
        "  print(\"F: Fault distance\")\n",
        "  print(\"T: water Table decline\")\n",
        "  print(\"SVI: Subsidence Vulnerability Index\")\n",
        "print(\"The shape of DataFrame is :\", data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IibMn-NL3K9u"
      },
      "source": [
        "# Dealing with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEHxh7Zxk568",
        "outputId": "d2a37690-933a-4258-be8c-054eaef28462"
      },
      "outputs": [],
      "source": [
        "# -3.402823e+38 in all columns except for land use represents a missing value\n",
        "# We wnat to put NaN instead of those missing pixels\n",
        "# To get the exact value of -3.402823e+38, we use data['A'][0]\n",
        "data.replace(data['A'][0], np.nan, inplace=True)\n",
        "\n",
        "# we drop all rows that at least 1 NaN value exist\n",
        "data.dropna(how='any', inplace=True)\n",
        "index = data.index\n",
        "print(\"The size of DataFrame after droping nan values :\", data.shape)\n",
        "print(\"=========================================================\")\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djsPQwRnRi9E"
      },
      "source": [
        "# Summery of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "bG_iKEkHRnq7",
        "outputId": "c86fb471-f41b-45f0-8ddf-16c44b4bc926"
      },
      "outputs": [],
      "source": [
        "# Unique types of land use\n",
        "print(\"Modes of land use :\", data['L'].unique())\n",
        "\n",
        "# summery of numerical columns\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjhGdpSC4lo5"
      },
      "source": [
        "# Create categorical SVI variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjlhSfQm4mz-",
        "outputId": "62ac7baa-e20e-4fda-d4dc-9ba1e359bd7b"
      },
      "outputs": [],
      "source": [
        "data['SVI'] = pd.cut(x=data['SVI'],\n",
        "                     bins=[2*data['SVI'].min(), -0.12, -0.08, -0.04, 0, data['SVI'].max()*2],\n",
        "                     labels=[4, 3, 2, 1, 0])\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg4V06p1ZWHB"
      },
      "source": [
        "# Specify features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UJEVPZonZcsp",
        "outputId": "d88d22f3-302e-4b81-b310-5c6a656b17fc"
      },
      "outputs": [],
      "source": [
        "target = data['SVI']\n",
        "features = data.drop('SVI', axis=1)\n",
        "\n",
        "# Saving feature names for later use\n",
        "feature_list = list(features.columns)\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8R3330lX9wl"
      },
      "source": [
        "# Convert categorical variable of land use into dummy/indicator variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i4xYf8N9X-V6",
        "outputId": "c778b36d-7eb5-4f4c-902f-5f2f16afc778"
      },
      "outputs": [],
      "source": [
        "features = pd.get_dummies(features, prefix=\"LU\", prefix_sep='_', dtype='float32', drop_first=True)\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgNStEjWafpW"
      },
      "source": [
        "# Devide data into train and test subsets\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCtsGE9LagVk"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features,target,test_size=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3HP9Y96bLAJ"
      },
      "source": [
        "# Preprocessing of the data (Scalling the features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PYWFdkzbasz"
      },
      "outputs": [],
      "source": [
        "# Apply StandardScaller to scale numerical variables (Note: this is not needed for dummy variables of land use)\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_train.iloc[:,:6] = scaler.fit_transform(X_train.iloc[:,:6])\n",
        "X_test.iloc[:,:6] = scaler.transform(X_test.iloc[:,:6])\n",
        "features.iloc[:,:6] = scaler.transform(features.iloc[:,:6]) # scale feature file also which is needed later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbFMXF4Icjdh"
      },
      "source": [
        "# Define a function to do modeling part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nwVqYErcj-8"
      },
      "outputs": [],
      "source": [
        "def doModeling(classifier, parameters, \n",
        "               X_train, X_test, y_train, y_test, features, \n",
        "               outFolderName, outFileName, Geotiff_file, Excel_out):\n",
        "\n",
        "    # Hyperparameters tunning by GridSearchCV\n",
        "    grid_clf = GridSearchCV(estimator=classifier, param_grid=parameters)\n",
        "    grid_clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"The model's best parameters are: \", grid_clf.best_params_)\n",
        "    \n",
        "    # do prediction for test data\n",
        "    y_pred = grid_clf.predict(X_test)\n",
        "\n",
        "    # produce confussion matrix\n",
        "    CM = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # calculate accuracy metrics\n",
        "    scores = cross_val_score(grid_clf, X_test, y_test, cv=5, scoring = 'accuracy')\n",
        "\n",
        "    AUC = roc_auc_score(y_test, grid_clf.predict_proba(X_test), multi_class='ovr')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Plot One-vs-Rest ROC curve\n",
        "    y_score = grid_clf.predict_proba(X_test)\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_train)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "    y_onehot_test.shape  # (n_samples, n_classes)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    for class_of_interest in range(0, 5):\n",
        "        class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
        "        class_id\n",
        "\n",
        "\n",
        "        RocCurveDisplay.from_predictions(\n",
        "            y_onehot_test[:, class_id],\n",
        "            y_score[:, class_id],\n",
        "            name=f\"{class_of_interest} vs the rest\",\n",
        "            ax=ax,\n",
        "            #color=\"darkorange\",\n",
        "            #plot_chance_level=True,\n",
        "        )\n",
        "    ax.axis(\"square\")\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(\"One-vs-Rest ROC curves\")\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Do prediction for all points\n",
        "    predition_all = np.empty(Geotiff_file['rows'] * Geotiff_file['cols'])\n",
        "    predition_all[:] = np.nan\n",
        "    predition_all[index] = grid_clf.predict(features)\n",
        "    predition_all = predition_all.reshape((Geotiff_file['rows'], Geotiff_file['cols']))\n",
        "\n",
        "    # Check if outFolder is exist\n",
        "    if os.path.exists(outFolderName) == False:\n",
        "      os.mkdir(outFolderName)\n",
        "\n",
        "    # call function to write output into geotiff file\n",
        "    WriteGeoTiff(arr_out = predition_all,\n",
        "                 outFileName = outFolderName + '/' + outFileName,\n",
        "                 cols = Geotiff_file['cols'],\n",
        "                 rows = Geotiff_file['rows'],\n",
        "                 geotransform = Geotiff_file['geotransform'],\n",
        "                 Projection = Geotiff_file['Projection'])\n",
        "\n",
        "    # write results in excel\n",
        "    with pd.ExcelWriter(outFolderName + '/' + Excel_out) as writer:\n",
        "        pd.DataFrame(CM).to_excel(writer, sheet_name='confusion_matrix')\n",
        "        pd.DataFrame(scores).to_excel(writer, sheet_name='scores')\n",
        "        pd.DataFrame.from_dict({'AUC': AUC, 'f1':f1, 'MeanScore': scores.mean()}, orient='index').to_excel(writer, sheet_name='metrics')\n",
        "\n",
        "    return {'model':classifier,\n",
        "            'model_best_parameters': grid_clf.best_params_,\n",
        "            'classification_report': classification_report(y_test, y_pred),\n",
        "            'confusionMatrix': CM, 'Scores': scores, 'MeanScore': scores.mean(),\n",
        "            'AUC': AUC, 'F1': f1, 'Predicted_values': predition_all}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lKwMYe47kEa"
      },
      "source": [
        "# A function to plot the predicted results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdtwyZN0rg2P"
      },
      "outputs": [],
      "source": [
        "def my_plotter(SVI_2D, AUC, model_name, SVI_geotiff, outFile):\n",
        "  \n",
        "  # make a color map of fixed colors to be used in all plots\n",
        "  my_cmap = colors.ListedColormap(['blue', 'green', 'gold', 'orange', 'red'])\n",
        "\n",
        "  # define color map\n",
        "  color_map = {0: np.array([0, 0, 255]), # blue\n",
        "              1: np.array([0, 255, 0]), # green\n",
        "              2: np.array([255, 215, 0]), # gold\n",
        "              3: np.array([255, 165, 0]), # orange\n",
        "              4: np.array([0, 0, 255]), # red\n",
        "              }\n",
        "\n",
        "  # make a 3d numpy array that has a color channel dimension\n",
        "  SVI_3D = np.ndarray(shape=(SVI_2D.shape[0], SVI_2D.shape[1], 3), dtype=int)\n",
        "  for i in range(0, SVI_2D.shape[0]):\n",
        "      for j in range(0, SVI_2D.shape[1]):\n",
        "        if isnan(SVI_2D[i][j]) == 0:\n",
        "          SVI_3D[i][j] = color_map[SVI_2D[i][j]]\n",
        "        else:\n",
        "          SVI_3D[i][j] = [255, 255, 255]\n",
        "\n",
        "  # display the plot\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  im = ax.imshow(SVI_3D, cmap= my_cmap)\n",
        "  xticks = np.linspace(0, SVI_2D.shape[1], num=5)\n",
        "  xtickLabels = np.round(np.linspace(SVI_geotiff['long_minmax'][0], SVI_geotiff['long_minmax'][1], num=5),2)\n",
        "  plt.xticks(xticks, xtickLabels)\n",
        "  plt.xlabel('longitude [decimal degree]')\n",
        "  plt.ylabel('latitude [decimal degree]')\n",
        "  yticks = np.linspace(0, SVI_2D.shape[0], num=5)\n",
        "  ytickLabels = np.round(np.linspace(SVI_geotiff['lat_minmax'][1], SVI_geotiff['lat_minmax'][0], num=5),2)\n",
        "  plt.yticks(yticks, ytickLabels)\n",
        "  ax.title.set_text('{} Model [AUC_t = '.format(model_name) + str(np.round(AUC, 3)) + ']')\n",
        "\n",
        "  # create an axes on the right side of ax. The width of cax will be 5%\n",
        "  # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "  cbar = fig.colorbar(im, cax=cax, ticks=np.linspace(0, 255, 6), orientation='vertical')\n",
        "  cbar.ax.set_yticklabels(['+'+ u'\\u2191', '0', '- 0.04', '- 0.08', '- 0.12', '-'+ u'\\u2193']) # unicode Character 'DOWNWARDS ARROW' and 'UPWARD ARROW' are  (U+2193) and (U+2191), respectively\n",
        "  cbar.ax.set_title('SVI', rotation=0)\n",
        "  cbar.ax.invert_yaxis()\n",
        "  fig.savefig(outFile, dpi=300)   # save the figure to file\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74ZC0gQlLaP"
      },
      "source": [
        "# Random Forest (RF) Model Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "bUl5esm3lL-r",
        "outputId": "bea19ca6-ca62-4b1a-d552-b4a339be9243"
      },
      "outputs": [],
      "source": [
        "RF = doModeling(classifier = RandomForestClassifier(n_estimators=10, random_state=0),\n",
        "                parameters = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}],\n",
        "                X_train = X_train,\n",
        "                X_test= X_test,\n",
        "                y_train= y_train,\n",
        "                y_test = y_test,\n",
        "                features = features,\n",
        "                outFolderName = '../Output',\n",
        "                outFileName = 'SVI_RF.tiff',\n",
        "                Geotiff_file = SVI_geotiff,\n",
        "                Excel_out = 'RF.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdpX2kHRfm07"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "TljCVVBd7a-D",
        "outputId": "9801d0d9-88da-4431-97a5-8d7d3ef083c0"
      },
      "outputs": [],
      "source": [
        "my_plotter(RF['Predicted_values'], RF['AUC'], 'RF', SVI_geotiff, '../Output/SVI_RF.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L_NynzCDisH"
      },
      "source": [
        "# Suport Vectro Machine (SVM) Model Development\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "nq7_7EIUDjLv",
        "outputId": "d97af29c-ef9d-43ce-834c-dfedb53b3a57"
      },
      "outputs": [],
      "source": [
        "SVM = doModeling(classifier = SVC(random_state=0,\n",
        "                                  probability=True,\n",
        "                                  decision_function_shape='ovr'), # decision_function_shape='ovo' uses one-versus-one strategy for multiclass classification\n",
        "                parameters = {'C':[0.1,1,10],'kernel':['rbf','linear','poly'],'gamma':[0.001,0.1,0.5]},\n",
        "                X_train = X_train,\n",
        "                X_test= X_test,\n",
        "                y_train= y_train,\n",
        "                y_test = y_test,\n",
        "                features = features,\n",
        "                outFolderName = '../Output',\n",
        "                outFileName = 'SVI_SVM.tiff',\n",
        "                Geotiff_file = SVI_geotiff,\n",
        "                Excel_out = 'SVM.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DflaejtY_-kz"
      },
      "source": [
        "# Plot results for SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Aiex2ISnam1K",
        "outputId": "2a19b8df-28c8-4fb4-a744-990664c022d6"
      },
      "outputs": [],
      "source": [
        "my_plotter(SVM['Predicted_values'], SVM['AUC'], 'SVM', SVI_geotiff, '../Output/SVI_SVM.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_AfoZpmmz8h"
      },
      "source": [
        "# Inclusive Multiple Modeling (Ensemble modeling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L6-BmcJ7m_SX",
        "outputId": "34a4113a-9684-4bb3-ee20-11ddb030f75c"
      },
      "outputs": [],
      "source": [
        "Ens_features = pd.DataFrame({'RF': np.array(RF['Predicted_values'], dtype='int').flatten()[index],\n",
        "                         'SVM': np.array(SVM['Predicted_values'], dtype='int').flatten()[index]}, dtype='object')\n",
        "Ens_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh-BBjdkpD4F"
      },
      "source": [
        "# Convert categorical variable of land use into dummy/indicator variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WFYMxw6vpE2q",
        "outputId": "d2799c47-b94e-4ffc-94f8-93882d1d167f"
      },
      "outputs": [],
      "source": [
        "Ens_features = pd.get_dummies(Ens_features, prefix_sep='_', dtype='float32', drop_first=True)\n",
        "Ens_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmUoK9w3qS3k"
      },
      "source": [
        "# Devide data into train and test subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY_5u65AqI8U"
      },
      "outputs": [],
      "source": [
        "Ens_X_train, Ens_X_test, Ens_y_train, Ens_y_test = train_test_split(Ens_features, target, test_size=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-jF8KHSqda6"
      },
      "source": [
        "# Ensemble modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "-GzgCJxSqgxY",
        "outputId": "05322b9a-b57b-423c-c9e6-ca9188195b6d"
      },
      "outputs": [],
      "source": [
        "IMM = doModeling(classifier = RandomForestClassifier(n_estimators=10, random_state=0),\n",
        "                parameters = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}],\n",
        "                X_train = Ens_X_train,\n",
        "                X_test= Ens_X_test,\n",
        "                y_train= Ens_y_train,\n",
        "                y_test = Ens_y_test,\n",
        "                features = Ens_features,\n",
        "                outFolderName = '../Output',\n",
        "                outFileName = 'SVI_IMM.tiff',\n",
        "                Geotiff_file = SVI_geotiff,\n",
        "                Excel_out = 'IMM.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dac8QytHry8T"
      },
      "source": [
        "# Plot results for SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "6PaMQKXMrz_S",
        "outputId": "8a0a3671-28ef-4656-cf13-81496805d8d1"
      },
      "outputs": [],
      "source": [
        "my_plotter(IMM['Predicted_values'], IMM['AUC'], 'IMM', SVI_geotiff, '../Output/SVI_IMM.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
